{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilthBvnZCQto"
   },
   "source": [
    "# Algorithms for Big Data - Exercise 8\n",
    "This lecture is focused on the more advanced examples of the RNN usage for text generation.\n",
    "\n",
    "We will use Harry Potter books in this lectures for generating our own stories.\n",
    "\n",
    "You can download the dataset from this course [Github](https://github.com/rasvob/2020-21-ARD/tree/master/datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_logger(path='log.txt'):\n",
    "    nblog = open(path, \"a+\")\n",
    "    sys.stdout.echo = nblog\n",
    "    sys.stderr.echo = nblog\n",
    "\n",
    "    get_ipython().log.handlers[0].stream = nblog\n",
    "    get_ipython().log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/2020-21-ARD/blob/master/abd_08.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/2020-21-ARD/blob/master/abd_08.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rkaSbn0fIgj4",
    "outputId": "4626484b-b008-460c-acb5-b969312d39c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "import numpy as np #numpy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
    "import tensorflow.keras as keras # required for high level applications\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2VO0IQ3TIgj6"
   },
   "outputs": [],
   "source": [
    "import unicodedata, re, string\n",
    "import nltk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P_Snoc6nIgj7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PgKNgw8eIgj7"
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxTGNxP2Igj8",
    "outputId": "2446bcec-a5e3-4544-ca09-7a31ff344e74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/usp/pro0255/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44mjoPEPIgj9"
   },
   "source": [
    "# We need to download the data first and split text to lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "d_gfiNWPIgj-"
   },
   "outputs": [],
   "source": [
    "req = requests.get('https://raw.githubusercontent.com/rasvob/2020-21-ARD/master/datasets/hp1.txt', allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KCwJd5cEIgj-"
   },
   "outputs": [],
   "source": [
    "txt = str(req.text).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmTH6kirIgj_",
    "outputId": "8f44f7d3-a123-4c2c-9033-663d9de07701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry Potter and the Sorcerer's Stone\",\n",
       " '',\n",
       " '',\n",
       " 'CHAPTER ONE',\n",
       " '',\n",
       " 'THE BOY WHO LIVED',\n",
       " '',\n",
       " 'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say',\n",
       " 'that they were perfectly normal, thank you very much. They were the last',\n",
       " \"people you'd expect to be involved in anything strange or mysterious,\",\n",
       " \"because they just didn't hold with such nonsense.\",\n",
       " '',\n",
       " 'Mr. Dursley was the director of a firm called Grunnings, which made',\n",
       " 'drills. He was a big, beefy man with hardly any neck, although he did',\n",
       " 'have a very large mustache. Mrs. Dursley was thin and blonde and had',\n",
       " 'nearly twice the usual amount of neck, which came in very useful as she',\n",
       " 'spent so much of her time craning over garden fences, spying on the',\n",
       " 'neighbors. The Dursleys had a small son called Dudley and in their',\n",
       " 'opinion there was no finer boy anywhere.',\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQAid-81Igj_"
   },
   "source": [
    "## We can see that the text is far from perfect because we have some noise in the data as in the last lecture\n",
    "We need to preprocess the text to be suitable for the RNN application. We need to clear blank lines and remove chapter headers. To simplify the task, we will get rid partialy of the interpunction as well for now. Final step will be joining the text into one big string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mwwSXrLIgkA",
    "outputId": "ed3cbaa8-1f4b-4513-b450-7528b88d3793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER ONE',\n",
       " '',\n",
       " 'THE BOY WHO LIVED',\n",
       " '',\n",
       " 'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say',\n",
       " 'that they were perfectly normal, thank you very much. They were the last',\n",
       " \"people you'd expect to be involved in anything strange or mysterious,\",\n",
       " \"because they just didn't hold with such nonsense.\",\n",
       " '',\n",
       " 'Mr. Dursley was the director of a firm called Grunnings, which made']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = txt[3:]\n",
    "txt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sou0qQUBIgkB"
   },
   "source": [
    "#### Remove the chapter header with chapter name\n",
    "We will remove the blank lines in this part as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1ejeZCDIgkB",
    "outputId": "f7514060-165d-418d-e549-755bf86c5358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'THE BOY WHO LIVED',\n",
       " '',\n",
       " 'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say',\n",
       " 'that they were perfectly normal, thank you very much. They were the last',\n",
       " \"people you'd expect to be involved in anything strange or mysterious,\",\n",
       " \"because they just didn't hold with such nonsense.\",\n",
       " '',\n",
       " 'Mr. Dursley was the director of a firm called Grunnings, which made',\n",
       " 'drills. He was a big, beefy man with hardly any neck, although he did']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [x for x in txt if 'CHAPTER ' not in x]\n",
    "txt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYQUcEkXIgkC",
    "outputId": "930fb7be-cd0e-440c-b61f-52f0aadd24ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say',\n",
       " 'that they were perfectly normal, thank you very much. They were the last',\n",
       " \"people you'd expect to be involved in anything strange or mysterious,\",\n",
       " \"because they just didn't hold with such nonsense.\",\n",
       " 'Mr. Dursley was the director of a firm called Grunnings, which made',\n",
       " 'drills. He was a big, beefy man with hardly any neck, although he did',\n",
       " 'have a very large mustache. Mrs. Dursley was thin and blonde and had',\n",
       " 'nearly twice the usual amount of neck, which came in very useful as she',\n",
       " 'spent so much of her time craning over garden fences, spying on the',\n",
       " 'neighbors. The Dursleys had a small son called Dudley and in their']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [x for x in txt if not x.upper() == x]\n",
    "txt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0if6lGlYIgkC"
   },
   "source": [
    "### There are another minor imperfections connected to the  -- 't -- suffix, we need to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ymREW1SIgkC",
    "outputId": "1bb91117-730b-46e4-bd70-60d64809b400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a squeaky voice that made passersby stare, \"Don\\'t be sorry, my dear sir,',\n",
       " \"didn't approve of imagination.\",\n",
       " \"and it didn't improve his mood -- was the tabby cat he'd spotted that\",\n",
       " '\"Shoo!\" said Mr. Dursley loudly. The cat didn\\'t move. It just gave him a',\n",
       " \"about Mrs. Next Door's problems with her daughter and how Dudley had\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in txt if \"\\'\" in x][25:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_2f6Fy3IgkD",
    "outputId": "750e71aa-ed79-4cc2-9c40-0807e2046155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a squeaky voice that made passersby stare, Don't be sorry, my dear sir,\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [x.replace('\"', '') for x in txt]\n",
    "[x for x in txt if \"a squeaky voice that\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYnbTnahIgkD"
   },
   "source": [
    "### We will join the text to one long line and tokenize it like the last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6xqWKWpXIgkE"
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def fix_nt(words):\n",
    "    st_res = []\n",
    "    for i in range(0, len(words) - 1):\n",
    "        if words[i+1] == \"n't\" or words[i+1] == \"nt\":\n",
    "            st_res.append(words[i]+(\"n't\"))\n",
    "        else:\n",
    "            if words[i] != \"n't\" and words[i] != \"nt\":\n",
    "                st_res.append(words[i])\n",
    "    return st_res\n",
    "\n",
    "def fix_s(words):\n",
    "    st_res = []\n",
    "    for i in range(0, len(words) - 1):\n",
    "        if words[i+1] == \"'s\":\n",
    "            st_res.append(words[i]+(\"'s\"))\n",
    "        else:\n",
    "            if words[i] != \"'s\":\n",
    "                st_res.append(words[i])\n",
    "    return st_res\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = fix_nt(words)   \n",
    "    words = fix_s(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mucripKOIgkF"
   },
   "outputs": [],
   "source": [
    "txt_one_line = ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "FEm0fmubIgkF",
    "outputId": "45396b22-576c-4ce4-fdda-83e06921649a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr. Dursley was the director of a fir\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_one_line[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xubAPm54IgkG"
   },
   "outputs": [],
   "source": [
    "tokenized = TextBlob(txt_one_line).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XlBomqKwIgkG"
   },
   "outputs": [],
   "source": [
    "tokenized = normalize(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gpPMqeFL70N",
    "outputId": "53da62ea-181f-497b-dd60-488d3cb85594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', 'and', 'Mrs', 'Dursley', 'of']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnIaH4StIgkG"
   },
   "source": [
    "### n't suffix should be fixed now (far from ideal TextBlob functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Frcbs5seIgkH",
    "outputId": "6138a5ee-0195-48bf-85a5-013f9017d6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"didn't\",\n",
       " \"didn't\",\n",
       " \"Dursley's\",\n",
       " \"hadn't\",\n",
       " \"didn't\",\n",
       " \"didn't\",\n",
       " \"four's\",\n",
       " \"didn't\",\n",
       " \"wasn't\",\n",
       " \"couldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tokenized if \"'s\" in x or \"n't\" in x][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFFqKZgCIgkH"
   },
   "source": [
    "### Final step of the preprocessing is joining the tokenized text back into fixed length sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeWbO_k_IgkH"
   },
   "source": [
    "### We differ among 4 modes of predictions in case of RNN\n",
    " - 1:1 - One word is classified as one of the classes, e.g. POS tag\n",
    " - 1:N - One word is classified in multiple classes, not very common\n",
    " - N:1 - Very commom, e.g. sentiment analysis\n",
    " - N:N - Also very common, e.g. machine translation, text generation\n",
    " \n",
    "![rnn_pred](https://github.com/rasvob/2020-21-ARD/raw/master/images/rnn_pred.jpeg)\n",
    " \n",
    "We need to define training vectors which are of the same length. There are multiple approaches for text generation - N:1 or N:N. The problem of the N:N approach is that it will generate fixed length sequences. Thus it's wise to transform the task into N:1 classification task, with N words in the training vector. Network will predict the next word for the input sequence which is basicaly a classification task.\n",
    "\n",
    "#### Sequence length is very important hyper-parameter!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziUTcREIIgkI"
   },
   "source": [
    "# Let's take a look at the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-fdT2QnYIgkI"
   },
   "outputs": [],
   "source": [
    "dist = nltk.FreqDist(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTHaRSTDMwXx",
    "outputId": "43830eb9-272f-406d-f24c-9f0a17888029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 3312, 'to': 1845, 'and': 1806, 'a': 1578, 'of': 1242, 'Harry': 1212, 'was': 1178, 'he': 1161, 'in': 933, 'I': 922, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6eISsReIgkI"
   },
   "source": [
    "### We have 6829 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKXVc5UeIgkJ",
    "outputId": "aff78c0a-aa3e-4a57-a66f-9670f9a2a46b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6830"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JdV3rHN9IgkJ"
   },
   "outputs": [],
   "source": [
    "most_common_words = sorted(list(dist.items()), key=lambda x: x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "r8BTBU2RIgkJ",
    "outputId": "f5c99317-704a-4f0a-e1ee-05a6e0edb2d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(1, figsize=(20, 14))\n",
    "sns.barplot(x=[x[0] for x in most_common_words], y=[x[1] for x in most_common_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69HbEjJpIgkK"
   },
   "source": [
    "## We have 78301 words in the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3CSxMDKiIgkK",
    "outputId": "bcbcc2cd-e22b-4e3d-fda9-fc3349920e5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78298"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPV3afdYsuDc",
    "outputId": "5e9a4166-e06c-4f4f-8002-885eb2d6eb16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', 'and']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-fXpBzecIgkK"
   },
   "outputs": [],
   "source": [
    "def create_vectors(tokens, sequence_length:int) -> Tuple[List, str]:\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(0, len(tokens) - sequence_length - 1):\n",
    "        seq, word = tokens[i:i+sequence_length], tokens[i + sequence_length]\n",
    "        X.append(' '.join(seq))\n",
    "        y.append(word)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ut-tfm2CIgkL"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZIfHVmEBIgkL"
   },
   "outputs": [],
   "source": [
    "X, y = create_vectors(tokenized, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Mjgu__QJIgkL",
    "outputId": "2a33b28d-0c85-498e-92ef-076488b24323"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7qDKFlpzIgkL",
    "outputId": "3a7fe627-2d30-4f52-d5c5-2f646fa7f67b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you very'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9EaC3CZYIgkL",
    "outputId": "60c74693-810c-44f2-d33e-fe9ea9878cc0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'very'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MHiDrQkIgkL",
    "outputId": "11e85c72-2111-4e03-a722-d80919d1228b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78277"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ITBqu1NbIgkL"
   },
   "outputs": [],
   "source": [
    "from tensorflow import string as tf_string\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VgZX9WO0IgkM"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50 # Dimension of embedded representation - this is already part of latent space, there is captured some dependecy among words, we are learning this vectors in ANN\n",
    "vocab_size = 7000 # Number of unique tokens in vocabulary\n",
    "sequence_length = SEQ_LEN # Output dimension after vectorizing - words in vectorited representation are independent\n",
    "\n",
    "vect_layer = TextVectorization(standardize=None, max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "vect_layer.adapt(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfib9qHCIgkM"
   },
   "source": [
    "# Final step is integer encoding of the target words into numbers according to the defined vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECqZ4cyEIgkM",
    "outputId": "feb5fd2b-33fa-4bab-97c9-47bcb9d65a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'and', 'a', 'of', 'Harry', 'was', 'he']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "C7nGQy4yIgkM"
   },
   "outputs": [],
   "source": [
    "vocab = vect_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8fhYZ0jGIgkN"
   },
   "outputs": [],
   "source": [
    "dict_vocab = {vocab[i]: i  for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1y6v6KlIgkN",
    "outputId": "6ec36100-d840-40c0-c70c-6546e95d4267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6833"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dfacGiHJIgkN"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = len(vect_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "c6FwSIAQIgkN"
   },
   "outputs": [],
   "source": [
    "y_enc = [dict_vocab[x] for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kw9uxszOIgkO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "3EqA9dSkIgkO"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_enc, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCGjRWgBIgkO"
   },
   "source": [
    "# We can define our model and train it using created sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LewZW_CtIgkO",
    "outputId": "fadbd980-db1d-4e91-a0ff-923c68c2de19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 20)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 50)            350000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20, 512)           1153024   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6833)              444145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,751,073\n",
      "Trainable params: 2,751,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
    "x_v = vect_layer(input_layer)\n",
    "emb = keras.layers.Embedding(vocab_size, embedding_dim)(x_v)\n",
    "x = LSTM(512, return_sequences=True)(emb)\n",
    "x = LSTM(256, return_sequences=False)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(64, 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output_layer = keras.layers.Dense(vocabulary_size, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5bPmLzXIgkO",
    "outputId": "d61645e6-95dc-4f8a-c137-ea797b77d52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "490/490 [==============================] - 31s 47ms/step - loss: 6.8984 - accuracy: 0.0414 - val_loss: 6.7504 - val_accuracy: 0.0432\n",
      "Epoch 2/5\n",
      "490/490 [==============================] - 21s 44ms/step - loss: 6.6424 - accuracy: 0.0436 - val_loss: 6.7289 - val_accuracy: 0.0462\n",
      "Epoch 3/5\n",
      "490/490 [==============================] - 22s 45ms/step - loss: 6.4806 - accuracy: 0.0500 - val_loss: 6.5418 - val_accuracy: 0.0545\n",
      "Epoch 4/5\n",
      "490/490 [==============================] - 22s 45ms/step - loss: 6.3643 - accuracy: 0.0557 - val_loss: 6.4521 - val_accuracy: 0.0586\n",
      "Epoch 5/5\n",
      "490/490 [==============================] - 22s 46ms/step - loss: 6.3039 - accuracy: 0.0604 - val_loss: 6.4395 - val_accuracy: 0.0612\n"
     ]
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=700, restore_best_weights=True)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights.best.tf',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), callbacks=[es, model_checkpoint_callback], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "K8MUvNkqIgkP",
    "outputId": "5231a6b4-0c2c-4f61-cdf0-16d54105a15b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "A6Hlf-QtIgkP",
    "outputId": "2f70bc18-8cc5-4b90-d2e1-e9b548e3701f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQROykOQIgkP",
    "outputId": "2fefd108-15cd-42b3-c73b-35e8c413009e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb8be645690>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights.best.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "b_wO7oIsIgkP"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHvg-su6IgkP"
   },
   "source": [
    "## Softmax gives you the probabilities which sums to 1 for every word in vocabulary\n",
    "We need to to choose the word with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qny1nkudIgkP",
    "outputId": "3ac0b2d5-ffb9-4fd3-dbc8-a2d97a09e1fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6187042e-06, 4.5612132e-06, 1.9495074e-02, ..., 7.0141355e-06,\n",
       "        4.5571346e-06, 8.1847529e-06]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "67fBfXinIgkQ"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DM6zeCWQIgkQ",
    "outputId": "0fa23184-bfd1-421b-82e1-41b2348cfaab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "n1m6AZvbIgkQ",
    "outputId": "bb82a221-1259-4a8d-8a28-fee7e6bfc4b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'was'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRyVgnQeIgkQ"
   },
   "source": [
    "#### We won't use probabilities directly but we will sample from the predicted outputs using Temperature Softmax [see this](https://medium.com/@majid.ghafouri/why-should-we-use-temperature-in-softmax-3709f4e0161)\n",
    "\n",
    "Basically, its ideas is that it would re-weight the probability distribution so that you can control how much surprising (i.e. higher temperature/entropy) or predictable (i.e. lower temperature/entropy) the next selected character would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kCRHKYr_IgkQ"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYgj2YD4IgkQ"
   },
   "source": [
    "We have to first generate a 20 vocab long sentence called seed text, then our model will use seed text to predict the next vocab, then we update the seed text with our newly generated vocab to predict the next vocab. Repeat this process to generate new text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "y0VkQ2X9IgkQ"
   },
   "outputs": [],
   "source": [
    "paragraph = X[0]\n",
    "whole_text = paragraph\n",
    "for i in range(50):\n",
    "    y_pred = model.predict([paragraph])\n",
    "    y_pred = sample(y_pred[0], 10)\n",
    "    word = vocab[y_pred]\n",
    "    paragraph += f' {word}'\n",
    "    whole_text += f' {word}'\n",
    "    tokens = paragraph.split()\n",
    "    paragraph = ' '.join(tokens[-SEQ_LEN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "R_arPuf6IgkQ",
    "outputId": "b3dc074a-0f2d-4b21-9b7a-df0547b1f86e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "ooD9MhVQIgkR",
    "outputId": "634dcf63-6af0-4e87-bd35-717ae63a9db0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you quivering Pretend dashed wrinkled bullied if sense Jigger pineapple tawny half sweater emptying informed recorded member ghosts icicles he lake Powerful hatches hovered chipolatas bent restaurant nearer Majorca Goshawk eyed holding defeat nudged smoother Knows feels nearby string Hedwig payin touches numbly shinin few sheer dwell pig's fly bending ward\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwvo1XH_IgkR"
   },
   "source": [
    "# We can even use pre-trained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2DU9N1sIgkR"
   },
   "source": [
    "# We need to download the embedding files\n",
    "~~~\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip\n",
    "~~~\n",
    "\n",
    "50 dims GLOVE is also avaiable here: https://vsb.ai/downloads/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBkFsi8mOqDI",
    "outputId": "be822f0c-6146-47f8-f7b4-3944ed10ed86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-16 10:16:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-03-16 10:16:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-03-16 10:16:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 40s  \n",
      "\n",
      "2022-03-16 10:19:15 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "IaF-Gjv9OquM"
   },
   "outputs": [],
   "source": [
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmZlTOEsIgkR"
   },
   "source": [
    "# First we need to load the file to memory and create embedding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPKzzw0UIgkR",
    "outputId": "e97238a1-6e24-41ad-a16d-78e06724b9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = 'glove.6B.50d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYe-XfgTIgkR"
   },
   "source": [
    "## We need to get the voacabulary from the Vectorizer and the integer indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ga6LXVKsIgkR"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50 # Dimension of embedded representation - this is already part of latent space, there is captured some dependecy among words, we are learning this vectors in ANN\n",
    "vocab_size = 7000 # Number of unique tokens in vocabulary\n",
    "sequence_length = SEQ_LEN # Output dimension after vectorizing - words in vectorited representation are independent\n",
    "\n",
    "vect_layer = TextVectorization(standardize=None, max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "vect_layer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "AMpPeeuQIgkS"
   },
   "outputs": [],
   "source": [
    "voc = vect_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQEyHO2fIgkS",
    "outputId": "7dc64559-e210-4b0b-ec6f-2318feec9390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6833"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FELsU8mbIgkS",
    "outputId": "0b0d42c2-50dd-4df7-901f-98ec7af2c05c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'and', 'a', 'of', 'Harry', 'was', 'he']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRb8_soQIgkS",
    "outputId": "263014f0-27fd-426c-d13d-8da83bd36305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 5152 words (1681 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_GlJ_A7IgkS",
    "outputId": "a2f43008-2163-422f-e4ed-a1fdf76487f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 20)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 20, 50)            341750    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20, 128)           91648     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 20, 128)           131584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               327808    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6833)              444145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345,191\n",
      "Trainable params: 1,345,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "show_historyyer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
    "x_v = vect_layer(input_layer)\n",
    "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=True)(x_v)\n",
    "x = LSTM(128, return_sequences=True)(emb)\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, 'relu')(x)\n",
    "x = keras.layers.Dense(64, 'relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "output_layer = keras.layers.Dense(vocabulary_size, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKon_tXnIgkS"
   },
   "source": [
    "#### Let's try to train the model for much longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STvMgHWHIgkT",
    "outputId": "59f673e9-ae27-402d-9e23-7cb84ea0de85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "490/490 [==============================] - 21s 34ms/step - loss: 6.9738 - accuracy: 0.0402 - val_loss: 6.8034 - val_accuracy: 0.0432\n",
      "Epoch 2/5\n",
      "490/490 [==============================] - 14s 29ms/step - loss: 6.7167 - accuracy: 0.0421 - val_loss: 6.7326 - val_accuracy: 0.0432\n",
      "Epoch 3/5\n",
      "490/490 [==============================] - 13s 26ms/step - loss: 6.6343 - accuracy: 0.0427 - val_loss: 6.6810 - val_accuracy: 0.0445\n",
      "Epoch 4/5\n",
      "490/490 [==============================] - 13s 26ms/step - loss: 6.5324 - accuracy: 0.0461 - val_loss: 6.6476 - val_accuracy: 0.0491\n",
      "Epoch 5/5\n",
      "490/490 [==============================] - 12s 25ms/step - loss: 6.4226 - accuracy: 0.0533 - val_loss: 6.5739 - val_accuracy: 0.0603\n"
     ]
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=700, restore_best_weights=True)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights2.best.tf',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "# epochs = 50\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), callbacks=[es, model_checkpoint_callback], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "zNtM-Zv0IgkT",
    "outputId": "4c16fa41-37ea-456b-d3ce-eb317437b5e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLQsruXWIgkT",
    "outputId": "b296b157-7d6c-44d1-ae6f-c1c28f67b363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb88c6fdb10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights2.best.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ZS5LOgUpIgkT"
   },
   "outputs": [],
   "source": [
    "paragraph = X[0]\n",
    "whole_text = paragraph\n",
    "for i in range(50):\n",
    "    y_pred = model.predict([paragraph])\n",
    "    y_pred = sample(y_pred[0], 1)\n",
    "    word = vocab[y_pred]\n",
    "    paragraph += f' {word}'\n",
    "    whole_text += f' {word}'\n",
    "    tokens = paragraph.split()\n",
    "    paragraph = ' '.join(tokens[-SEQ_LEN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TFfvFmUlIgkT",
    "outputId": "9519bc34-ce78-4989-f2f1-55a505c8f3e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "esXJRaUpIgkT",
    "outputId": "be2b517f-e697-4201-f0e1-71569234a207"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you of happened he told they too over from a relief thing then could Hufflepuffs Harry Weasley none a nasty light Malfoy white face-to-face more table blood their feeling Emporium clutched Something sheared Harry think Uncle empty doing but his books the marks tried the not toppled keep that Let the'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsQtB1ieIgkU"
   },
   "source": [
    "# Your can see that we are able to generate text of any length using this approach, unfortunately the task is quite complex for model of this simplicity and relatively small dataset\n",
    "## The text usually doesn't make much sense as you could see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACYfgOfyIgkU"
   },
   "source": [
    "# Another approach is to create character-level model which learns how to write from scratch\n",
    "## We will try to train this model and comprare obtained results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a3vlfuwIgkU"
   },
   "source": [
    "#### We will simplify the task for using only lower case letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "3l6gbE-YIgkU"
   },
   "outputs": [],
   "source": [
    "txt_one_line = txt_one_line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7d_cFyk8IgkU",
    "outputId": "77d86b5e-ba56-4781-baac-dc2a118a0f17"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'mr. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly norma'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_one_line[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "EiAf4fdGIgkV"
   },
   "outputs": [],
   "source": [
    "letters = []\n",
    "for x in txt_one_line:\n",
    "    if x >= 'a' and x <= 'z' or x == ' ':\n",
    "        letters.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtLW_bqsIgkV",
    "outputId": "c2bd4987-58e8-4bcd-e20f-df3e09deffc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'r', 's']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuQV6RprIgkV"
   },
   "source": [
    "# We have corpus of 412 325 characters available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xAFDYzPIgkV",
    "outputId": "99afdc68-badb-4b6b-bd56-28eee86c377e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412325"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktdfA1UHIgkV",
    "outputId": "1f08a6cc-0e43-43c9-93c5-98d01e68868b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(letters)))\n",
    "print(\"Total chars:\", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "2xNPNDjUIgkW"
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQJysHfuIgkW",
    "outputId": "6753222b-5c39-4ab6-f7aa-8164dde97af9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISMoJIvZIgkW"
   },
   "source": [
    "## We need to create fixed length sequences once again for prediction of the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "cvZel3DZIgkW"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 40\n",
    "step = 1\n",
    "X, y = [], []\n",
    "for i in range(0, len(letters) - SEQ_LEN, step):\n",
    "    seq, ch = letters[i:i+SEQ_LEN], letters[i + SEQ_LEN]\n",
    "    X.append(seq)\n",
    "    y.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NO6K2OT7IgkW",
    "outputId": "cf375e41-75c9-47d9-cdc1-fdcc3d8fdc12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'm',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'd',\n",
       " 'u',\n",
       " 'r',\n",
       " 's',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " 't']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpowqNWEIgkW",
    "outputId": "745f6380-ce1b-4abd-8717-a0cc3a059e40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'm',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'd',\n",
       " 'u',\n",
       " 'r',\n",
       " 's',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " 't',\n",
       " ' ']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BBQoBjyRIgkW",
    "outputId": "838f6931-6325-4e48-cc68-02eda44a2b7f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifwb5E-WIgkX"
   },
   "source": [
    "# OHE is used for the characted level RNN so we need to encode our characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwP0iYyeIgkX",
    "outputId": "026684cb-cfe6-412a-db42-3fac344bf21e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_ohe = np.zeros((len(X), SEQ_LEN, len(chars)), dtype=np.bool)\n",
    "y_ohe = np.zeros((len(X), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(X):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_ohe[i, t, char_indices[char]] = 1\n",
    "    y_ohe[i, char_indices[y[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odDspZcsIgkX",
    "outputId": "339ceca8-7a14-416f-efcb-5fc33f68d5af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False,  True, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJCKyV09IgkX",
    "outputId": "7f469511-2904-4a2d-b164-207e7d1d8ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnQ5SxDKIgkX",
    "outputId": "c7b20830-5363-4a31-c59c-3a5b0c3d8627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412285, 40, 27)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjoIM_IrIgkX",
    "outputId": "4f340174-3d5a-4fe4-f803-24a5b3d00da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 40, 27)]          0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 40, 128)           79872     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,859\n",
      "Trainable params: 280,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(SEQ_LEN, len(chars)))\n",
    "x = LSTM(128, return_sequences=True)(input_layer)\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, 'relu')(x)\n",
    "x = keras.layers.Dense(128, 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output_layer = keras.layers.Dense(len(chars), activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ck55kKzdIgkY",
    "outputId": "d136e265-3a98-4e21-ff1b-9f4bdda8d743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2577/2577 [==============================] - 84s 31ms/step - loss: 2.0799 - accuracy: 0.3780 - val_loss: 1.7191 - val_accuracy: 0.4746\n",
      "Epoch 2/10\n",
      "2577/2577 [==============================] - 77s 30ms/step - loss: 1.6330 - accuracy: 0.4979 - val_loss: 1.5318 - val_accuracy: 0.5258\n",
      "Epoch 3/10\n",
      "2577/2577 [==============================] - 78s 30ms/step - loss: 1.5011 - accuracy: 0.5356 - val_loss: 1.4808 - val_accuracy: 0.5414\n",
      "Epoch 4/10\n",
      "2577/2577 [==============================] - 72s 28ms/step - loss: 1.4453 - accuracy: 0.5512 - val_loss: 1.4595 - val_accuracy: 0.5510\n",
      "Epoch 5/10\n",
      "2577/2577 [==============================] - 74s 29ms/step - loss: 1.4232 - accuracy: 0.5595 - val_loss: 1.4591 - val_accuracy: 0.5607\n",
      "Epoch 6/10\n",
      "2577/2577 [==============================] - 80s 31ms/step - loss: 1.4186 - accuracy: 0.5618 - val_loss: 1.4544 - val_accuracy: 0.5578\n",
      "Epoch 7/10\n",
      "2577/2577 [==============================] - 76s 30ms/step - loss: 1.4193 - accuracy: 0.5620 - val_loss: 1.4749 - val_accuracy: 0.5577\n",
      "Epoch 8/10\n",
      "2577/2577 [==============================] - 78s 30ms/step - loss: 1.4213 - accuracy: 0.5619 - val_loss: 1.4657 - val_accuracy: 0.5626\n",
      "Epoch 9/10\n",
      "2577/2577 [==============================] - 76s 29ms/step - loss: 1.4227 - accuracy: 0.5622 - val_loss: 1.5084 - val_accuracy: 0.5604\n",
      "Epoch 10/10\n",
      "2577/2577 [==============================] - 74s 29ms/step - loss: 1.4250 - accuracy: 0.5631 - val_loss: 1.5022 - val_accuracy: 0.5623\n"
     ]
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=700, restore_best_weights=True)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights3.best.tf',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_ohe, y_ohe, validation_split=0.2, callbacks=[es, model_checkpoint_callback], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAd-fosoIgkY",
    "outputId": "ea066951-a47b-40fc-96b9-c5b549922858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb8be6707d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights3.best.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYad_JbhIgkY",
    "outputId": "6e6a39f2-514b-432c-bb6e-7a781a4b712e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [ True, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe[0].reshape((1, 40, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "0goSp3HDIgkY"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_ohe[0].reshape((1, 40, 27)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2f1vnmtIgkY",
    "outputId": "880ee052-6e3f-4bae-d5b6-74cb261183db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.54093730e-01, 7.30780812e-06, 6.24281737e-10, 2.90388061e-06,\n",
       "       2.51714466e-03, 5.96267986e-04, 1.33995659e-08, 1.56591375e-06,\n",
       "       1.46608116e-07, 7.50979088e-05, 4.32939753e-29, 3.22474003e-09,\n",
       "       2.81318818e-04, 1.21030580e-05, 8.05896940e-04, 1.82325439e-05,\n",
       "       1.39811206e-07, 1.63061627e-28, 2.21348149e-04, 1.40589669e-01,\n",
       "       7.76872039e-04, 1.04741185e-08, 6.08704059e-12, 5.23015808e-09,\n",
       "       1.02179350e-26, 2.31094333e-07, 1.93971430e-23], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DxogWXRxIgkY",
    "outputId": "813d62be-f372-4544-d134-586f9fc5a426"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = sample(y_pred)\n",
    "indices_char[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nKOvgiUIgkY",
    "outputId": "12f395bd-7538-494e-da6f-84cbd75e0f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "whole_text = X[10].copy()\n",
    "seq = X[10].copy()\n",
    "for i in range(500):\n",
    "    paragraph_ohe = np.zeros((1, SEQ_LEN, len(chars)))\n",
    "    for t, char in enumerate(seq):\n",
    "        paragraph_ohe[0, t, char_indices[char]] = 1\n",
    "    y_pred = model.predict(paragraph_ohe)\n",
    "    c = sample(y_pred[0], 0.5)\n",
    "    next_char = indices_char[c]\n",
    "    whole_text.append(next_char)\n",
    "    seq = whole_text[-SEQ_LEN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "X2t6FZjHIgkZ",
    "outputId": "66745372-dffd-4f2f-ea53-668d2c061e45"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' dursley of number four privet drive were in the sorting to into the directly no wood ginghard and he was something  of etwers some mong and hed had been haar wood on the borger the walk off in the thing the thing blank it around the wants harry badged and whievery seemed to year harry how why should the with a twing the class and her  and the first in under the ground and wa heads in the star and they went looked mofficn he had been bittercide behind the ways the fool his back him the said harry in the leam to not except dark the cor'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apQ-0mYaIgkZ"
   },
   "source": [
    "# Task for the lecture\n",
    " - Choose either word or character level model\n",
    " - Choose another, at least one, HP book (it's on my Github, link at the top)\n",
    " - Preprocess it according to the first one\n",
    " - Merge the books together\n",
    " - Use pre-defined model from lecture or your own and train it for the long time (epochs > 50)\n",
    " - Experiment a little - try different batch sizes, optimimizers\n",
    " - Show me the Colab notebook with results and description of what you did and your final solution during the next lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgBBM2wPR8ox"
   },
   "source": [
    "Porovnat texty po ruznem poctu epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQUDTLG8v0U7",
    "outputId": "fcdcfc02-6ac2-43e0-d936-0e30709bdcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430753\n"
     ]
    }
   ],
   "source": [
    "#First book\n",
    "txt_one_line[0:10]\n",
    "print(len(txt_one_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aLSZh4fgR-1x"
   },
   "outputs": [],
   "source": [
    "req2 = requests.get('https://raw.githubusercontent.com/rasvob/2020-21-ARD/master/datasets/hp2.txt', allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NzPVtMH5s8OU"
   },
   "outputs": [],
   "source": [
    "txt2 = str(req2.text).splitlines()\n",
    "\n",
    "txt2 = [x for x in txt2 if 'CHAPTER ' not in x]\n",
    "txt2 = [x for x in txt2 if not x.upper() == x]\n",
    "txt2 = [x.replace('\"', '') for x in txt2]\n",
    "txt_one_line_2 = ' '.join(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LcS51Jzv7my",
    "outputId": "7f1d1ecf-5b34-4896-dc7c-60f651b079a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481268\n"
     ]
    }
   ],
   "source": [
    "#Second book\n",
    "txt_one_line_2[0:1000]\n",
    "print(len(txt_one_line_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20evzuhCvfkX",
    "outputId": "4f8b57c4-ecf6-4ae2-c2dc-4b813f8e35a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912021\n"
     ]
    }
   ],
   "source": [
    "merged = txt_one_line + txt_one_line_2\n",
    "print(len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "w-zx9EL6uNYE"
   },
   "outputs": [],
   "source": [
    "merged = merged.lower()\n",
    "\n",
    "letters = []\n",
    "for x in merged:\n",
    "    if x >= 'a' and x <= 'z' or x == ' ':\n",
    "        letters.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZrGRXy_wf9O",
    "outputId": "b45f65f9-2373-4925-b07c-8f4ae3928ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874013"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2Rj6995uXEY",
    "outputId": "66697af1-5877-44b2-a702-a99f6e7f763a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(letters)))\n",
    "print(\"Total chars:\", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Ej20tGwjuZ6f"
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NG5ddHPpwsUy"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 60\n",
    "GENERATE_NUMBER_OF_CHARS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8D3KWgUmuk8R"
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "X, y = [], []\n",
    "for i in range(0, len(letters) - SEQ_LEN, step):\n",
    "    seq, ch = letters[i:i+SEQ_LEN], letters[i + SEQ_LEN]\n",
    "    X.append(seq)\n",
    "    y.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GwrKdvjzwyLm",
    "outputId": "9e4dbb2f-e2f0-407c-eb96-404baf37bd57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mr and mrs dursley of number four privet drive were proud to'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dKS2JrE1w4Pw",
    "outputId": "a624243b-d4bd-44f4-aef4-f1427bb86dba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bSvXMN2urW1",
    "outputId": "445fd10a-542a-463c-a2a3-caafb7c72915"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12096/3613875084.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_ohe = np.zeros((len(X), SEQ_LEN, len(chars)), dtype=np.bool)\n",
      "/tmp/ipykernel_12096/3613875084.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_ohe = np.zeros((len(X), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "X_ohe = np.zeros((len(X), SEQ_LEN, len(chars)), dtype=np.bool)\n",
    "y_ohe = np.zeros((len(X), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(X):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_ohe[i, t, char_indices[char]] = 1\n",
    "    y_ohe[i, char_indices[y[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Sj-VqM3juu6Z"
   },
   "outputs": [],
   "source": [
    "# input_layer = keras.layers.Input(shape=(SEQ_LEN, len(chars)))\n",
    "# x = LSTM(128, return_sequences=True)(input_layer)\n",
    "# x = LSTM(128, return_sequences=False)(x)\n",
    "# x = keras.layers.Flatten()(x)\n",
    "# x = keras.layers.Dense(256, 'relu')(x)\n",
    "# x = keras.layers.BatchNormalization(x)\n",
    "# x = keras.layers.Dense(128, 'relu')(x)\n",
    "# x = keras.layers.Dropout(0.2)(x)\n",
    "# output_layer = keras.layers.Dense(len(chars), activation=tf.nn.softmax)(x)\n",
    "\n",
    "# model = keras.Model(input_layer, output_layer)\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=700, restore_best_weights=True)\n",
    "\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='weights3.best.tf',\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_loss',\n",
    "#     mode='auto',\n",
    "#     save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "# history = model.fit(X_ohe, y_ohe, validation_split=0.2, callbacks=[es, model_checkpoint_callback], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Yi8ZUC5qu8fj"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"weights3.best.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "W9jtaRgBvBDT"
   },
   "outputs": [],
   "source": [
    "# whole_text = X[10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SGzn9Q15xlIR",
    "outputId": "655009d9-8df4-497a-f819-e056d3fe44c2"
   },
   "outputs": [],
   "source": [
    "# \"\".join(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vA6-nuzPvvz9"
   },
   "outputs": [],
   "source": [
    "# for i in range(GENERATE_NUMBER_OF_CHARS):\n",
    "#     paragraph_ohe = np.zeros((1, SEQ_LEN, len(chars)))\n",
    "#     for t, char in enumerate(seq):\n",
    "#         paragraph_ohe[0, t, char_indices[char]] = 1\n",
    "#     y_pred = model.predict(paragraph_ohe)\n",
    "#     c = sample(y_pred[0], 0.5)\n",
    "#     next_char = indices_char[c]\n",
    "#     whole_text.append(next_char)\n",
    "#     seq = whole_text[-SEQ_LEN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-oMg_PI7x_vZ"
   },
   "outputs": [],
   "source": [
    "TEST_EPOCHS = [\n",
    "  10,\n",
    "  20,\n",
    "  30,\n",
    "  40,\n",
    "  50\n",
    "]\n",
    "\n",
    "OPTIMIZERS = [\n",
    "'adam',\n",
    "'rmsprop'\n",
    "]\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "OdCtwpZv0AN5"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "vvJPWIV8zE1H"
   },
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "murkIrNGx-l7",
    "outputId": "81289fa8-da35-437d-e47e-3d3a307189f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - adam - 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 18:07:01.139314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-20 18:07:01.139347: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-20 18:07:01.139829: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 60, 27)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 60, 128)           79872     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,859\n",
      "Trainable params: 280,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "2732/2732 [==============================] - 852s 311ms/step - loss: 1.9999 - accuracy: 0.3993 - val_loss: 1.6228 - val_accuracy: 0.5023\n",
      "Epoch 2/10\n",
      "2732/2732 [==============================] - 782s 286ms/step - loss: 1.5395 - accuracy: 0.5237 - val_loss: 1.4412 - val_accuracy: 0.5515\n",
      "Epoch 3/10\n",
      "2732/2732 [==============================] - 754s 276ms/step - loss: 1.4133 - accuracy: 0.5592 - val_loss: 1.3655 - val_accuracy: 0.5728\n",
      "Epoch 4/10\n",
      "2732/2732 [==============================] - 760s 278ms/step - loss: 1.3478 - accuracy: 0.5768 - val_loss: 1.3273 - val_accuracy: 0.5840\n",
      "Epoch 5/10\n",
      "2732/2732 [==============================] - 784s 287ms/step - loss: 1.3053 - accuracy: 0.5891 - val_loss: 1.3082 - val_accuracy: 0.5923\n",
      "Epoch 6/10\n",
      "2732/2732 [==============================] - 781s 286ms/step - loss: 1.2740 - accuracy: 0.5978 - val_loss: 1.2872 - val_accuracy: 0.5956\n",
      "Epoch 7/10\n",
      "2732/2732 [==============================] - 910s 333ms/step - loss: 1.2489 - accuracy: 0.6047 - val_loss: 1.2788 - val_accuracy: 0.5999\n",
      "Epoch 8/10\n",
      "2732/2732 [==============================] - 988s 362ms/step - loss: 1.2286 - accuracy: 0.6101 - val_loss: 1.2662 - val_accuracy: 0.6039\n",
      "Epoch 9/10\n",
      "2732/2732 [==============================] - 982s 360ms/step - loss: 1.2108 - accuracy: 0.6146 - val_loss: 1.2631 - val_accuracy: 0.6074\n",
      "Epoch 10/10\n",
      "2732/2732 [==============================] - 955s 350ms/step - loss: 1.1962 - accuracy: 0.6184 - val_loss: 1.2562 - val_accuracy: 0.6085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12096/913138547.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - adam - 20\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 60, 27)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60, 128)           79872     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,859\n",
      "Trainable params: 280,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2732/2732 [==============================] - 920s 335ms/step - loss: 2.0002 - accuracy: 0.3999 - val_loss: 1.6109 - val_accuracy: 0.5041\n",
      "Epoch 2/20\n",
      "2732/2732 [==============================] - 967s 354ms/step - loss: 1.5429 - accuracy: 0.5230 - val_loss: 1.4431 - val_accuracy: 0.5499\n",
      "Epoch 3/20\n",
      "2732/2732 [==============================] - 958s 351ms/step - loss: 1.4190 - accuracy: 0.5580 - val_loss: 1.3804 - val_accuracy: 0.5686\n",
      "Epoch 4/20\n",
      "2732/2732 [==============================] - 941s 344ms/step - loss: 1.3538 - accuracy: 0.5759 - val_loss: 1.3354 - val_accuracy: 0.5823\n",
      "Epoch 5/20\n",
      "2732/2732 [==============================] - 1007s 369ms/step - loss: 1.3098 - accuracy: 0.5881 - val_loss: 1.3116 - val_accuracy: 0.5885\n",
      "Epoch 6/20\n",
      "2732/2732 [==============================] - 1010s 370ms/step - loss: 1.2781 - accuracy: 0.5973 - val_loss: 1.2904 - val_accuracy: 0.5977\n",
      "Epoch 7/20\n",
      "2732/2732 [==============================] - 1084s 397ms/step - loss: 1.2526 - accuracy: 0.6035 - val_loss: 1.2890 - val_accuracy: 0.5977\n",
      "Epoch 8/20\n",
      "2732/2732 [==============================] - 1036s 379ms/step - loss: 1.2320 - accuracy: 0.6098 - val_loss: 1.2741 - val_accuracy: 0.6021\n",
      "Epoch 9/20\n",
      "2732/2732 [==============================] - 1039s 380ms/step - loss: 1.2140 - accuracy: 0.6144 - val_loss: 1.2756 - val_accuracy: 0.6031\n",
      "Epoch 10/20\n",
      "2732/2732 [==============================] - 1318s 483ms/step - loss: 1.1991 - accuracy: 0.6188 - val_loss: 1.2667 - val_accuracy: 0.6060\n",
      "Epoch 11/20\n",
      "2732/2732 [==============================] - 1325s 485ms/step - loss: 1.1864 - accuracy: 0.6219 - val_loss: 1.2607 - val_accuracy: 0.6076\n",
      "Epoch 12/20\n",
      "2732/2732 [==============================] - 1308s 479ms/step - loss: 1.1739 - accuracy: 0.6252 - val_loss: 1.2579 - val_accuracy: 0.6104\n",
      "Epoch 13/20\n",
      "2732/2732 [==============================] - 1139s 417ms/step - loss: 1.1633 - accuracy: 0.6287 - val_loss: 1.2595 - val_accuracy: 0.6126\n",
      "Epoch 14/20\n",
      "2732/2732 [==============================] - 1052s 385ms/step - loss: 1.1527 - accuracy: 0.6314 - val_loss: 1.2553 - val_accuracy: 0.6144\n",
      "Epoch 15/20\n",
      "2732/2732 [==============================] - 921s 337ms/step - loss: 1.1430 - accuracy: 0.6339 - val_loss: 1.2606 - val_accuracy: 0.6142\n",
      "Epoch 16/20\n",
      "2732/2732 [==============================] - 880s 322ms/step - loss: 1.1352 - accuracy: 0.6359 - val_loss: 1.2564 - val_accuracy: 0.6162\n",
      "Epoch 17/20\n",
      "2732/2732 [==============================] - 879s 322ms/step - loss: 1.1261 - accuracy: 0.6384 - val_loss: 1.2636 - val_accuracy: 0.6161\n",
      "Epoch 18/20\n",
      "2732/2732 [==============================] - 860s 315ms/step - loss: 1.1184 - accuracy: 0.6407 - val_loss: 1.2654 - val_accuracy: 0.6146\n",
      "Epoch 19/20\n",
      "2732/2732 [==============================] - 865s 317ms/step - loss: 1.1113 - accuracy: 0.6423 - val_loss: 1.2697 - val_accuracy: 0.6138\n",
      "Epoch 20/20\n",
      "2732/2732 [==============================] - 894s 327ms/step - loss: 1.1046 - accuracy: 0.6443 - val_loss: 1.2676 - val_accuracy: 0.6162\n",
      "2 - adam - 30\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 60, 27)]          0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 60, 128)           79872     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,859\n",
      "Trainable params: 280,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2732/2732 [==============================] - 903s 329ms/step - loss: 1.9981 - accuracy: 0.4009 - val_loss: 1.6120 - val_accuracy: 0.5046\n",
      "Epoch 2/30\n",
      "2732/2732 [==============================] - 871s 319ms/step - loss: 1.5384 - accuracy: 0.5249 - val_loss: 1.4449 - val_accuracy: 0.5492\n",
      "Epoch 3/30\n",
      "2732/2732 [==============================] - 862s 315ms/step - loss: 1.4155 - accuracy: 0.5581 - val_loss: 1.3722 - val_accuracy: 0.5679\n",
      "Epoch 4/30\n",
      "2732/2732 [==============================] - 876s 321ms/step - loss: 1.3503 - accuracy: 0.5760 - val_loss: 1.3364 - val_accuracy: 0.5801\n",
      "Epoch 5/30\n",
      "2732/2732 [==============================] - 881s 323ms/step - loss: 1.3072 - accuracy: 0.5878 - val_loss: 1.3065 - val_accuracy: 0.5894\n",
      "Epoch 6/30\n",
      "2732/2732 [==============================] - 863s 316ms/step - loss: 1.2763 - accuracy: 0.5968 - val_loss: 1.2943 - val_accuracy: 0.5967\n",
      "Epoch 7/30\n",
      "2732/2732 [==============================] - 858s 314ms/step - loss: 1.2521 - accuracy: 0.6031 - val_loss: 1.2744 - val_accuracy: 0.6003\n",
      "Epoch 8/30\n",
      "2732/2732 [==============================] - 880s 322ms/step - loss: 1.2308 - accuracy: 0.6094 - val_loss: 1.2719 - val_accuracy: 0.6034\n",
      "Epoch 9/30\n",
      "2732/2732 [==============================] - 878s 322ms/step - loss: 1.2128 - accuracy: 0.6141 - val_loss: 1.2606 - val_accuracy: 0.6039\n",
      "Epoch 10/30\n",
      "2732/2732 [==============================] - 862s 316ms/step - loss: 1.1972 - accuracy: 0.6187 - val_loss: 1.2573 - val_accuracy: 0.6081\n",
      "Epoch 11/30\n",
      "2732/2732 [==============================] - 866s 317ms/step - loss: 1.1854 - accuracy: 0.6210 - val_loss: 1.2535 - val_accuracy: 0.6101\n",
      "Epoch 12/30\n",
      "2732/2732 [==============================] - 881s 322ms/step - loss: 1.1727 - accuracy: 0.6249 - val_loss: 1.2549 - val_accuracy: 0.6098\n",
      "Epoch 13/30\n",
      "2732/2732 [==============================] - 875s 320ms/step - loss: 1.1607 - accuracy: 0.6282 - val_loss: 1.2586 - val_accuracy: 0.6112\n",
      "Epoch 14/30\n",
      "2732/2732 [==============================] - 862s 316ms/step - loss: 1.1517 - accuracy: 0.6306 - val_loss: 1.2529 - val_accuracy: 0.6133\n",
      "Epoch 15/30\n",
      "2732/2732 [==============================] - 905s 331ms/step - loss: 1.1415 - accuracy: 0.6334 - val_loss: 1.2600 - val_accuracy: 0.6137\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2732/2732 [==============================] - 914s 335ms/step - loss: 1.1330 - accuracy: 0.6352 - val_loss: 1.2555 - val_accuracy: 0.6148\n",
      "Epoch 17/30\n",
      "2732/2732 [==============================] - 845s 309ms/step - loss: 1.1248 - accuracy: 0.6378 - val_loss: 1.2619 - val_accuracy: 0.6144\n",
      "Epoch 18/30\n",
      "2732/2732 [==============================] - 850s 311ms/step - loss: 1.1177 - accuracy: 0.6402 - val_loss: 1.2612 - val_accuracy: 0.6166\n",
      "Epoch 19/30\n",
      "2732/2732 [==============================] - 908s 332ms/step - loss: 1.1108 - accuracy: 0.6418 - val_loss: 1.2637 - val_accuracy: 0.6139\n",
      "Epoch 20/30\n",
      "2732/2732 [==============================] - 903s 331ms/step - loss: 1.1031 - accuracy: 0.6437 - val_loss: 1.2750 - val_accuracy: 0.6156\n",
      "Epoch 21/30\n",
      "2732/2732 [==============================] - 847s 310ms/step - loss: 1.0969 - accuracy: 0.6455 - val_loss: 1.2724 - val_accuracy: 0.6159\n",
      "Epoch 22/30\n",
      "2732/2732 [==============================] - 847s 310ms/step - loss: 1.0903 - accuracy: 0.6471 - val_loss: 1.2701 - val_accuracy: 0.6155\n",
      "Epoch 23/30\n",
      "2732/2732 [==============================] - 906s 332ms/step - loss: 1.0851 - accuracy: 0.6484 - val_loss: 1.2821 - val_accuracy: 0.6164\n",
      "Epoch 24/30\n",
      "2732/2732 [==============================] - 966s 353ms/step - loss: 1.0799 - accuracy: 0.6497 - val_loss: 1.2823 - val_accuracy: 0.6159\n",
      "Epoch 25/30\n",
      "2732/2732 [==============================] - 1239s 453ms/step - loss: 1.0743 - accuracy: 0.6518 - val_loss: 1.2810 - val_accuracy: 0.6163\n",
      "Epoch 26/30\n",
      "2732/2732 [==============================] - 1480s 542ms/step - loss: 1.0700 - accuracy: 0.6530 - val_loss: 1.2882 - val_accuracy: 0.6161\n",
      "Epoch 27/30\n",
      "2732/2732 [==============================] - 1478s 541ms/step - loss: 1.0649 - accuracy: 0.6538 - val_loss: 1.2866 - val_accuracy: 0.6175\n",
      "Epoch 28/30\n",
      "2732/2732 [==============================] - 1427s 522ms/step - loss: 1.0597 - accuracy: 0.6552 - val_loss: 1.2903 - val_accuracy: 0.6157\n",
      "Epoch 29/30\n",
      "2732/2732 [==============================] - 1421s 520ms/step - loss: 1.0554 - accuracy: 0.6568 - val_loss: 1.2939 - val_accuracy: 0.6159\n",
      "Epoch 30/30\n",
      "2732/2732 [==============================] - 1136s 416ms/step - loss: 1.0505 - accuracy: 0.6575 - val_loss: 1.3015 - val_accuracy: 0.6175\n",
      "3 - adam - 40\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 60, 27)]          0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 60, 128)           79872     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,859\n",
      "Trainable params: 280,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "2732/2732 [==============================] - 1344s 489ms/step - loss: 1.9737 - accuracy: 0.4067 - val_loss: 1.5898 - val_accuracy: 0.5069\n",
      "Epoch 2/40\n",
      "2732/2732 [==============================] - 1310s 479ms/step - loss: 1.5199 - accuracy: 0.5294 - val_loss: 1.4397 - val_accuracy: 0.5509\n",
      "Epoch 3/40\n",
      "2732/2732 [==============================] - 1321s 484ms/step - loss: 1.4005 - accuracy: 0.5625 - val_loss: 1.3682 - val_accuracy: 0.5717\n",
      "Epoch 4/40\n",
      "2732/2732 [==============================] - 1284s 470ms/step - loss: 1.3381 - accuracy: 0.5806 - val_loss: 1.3252 - val_accuracy: 0.5844\n",
      "Epoch 5/40\n",
      "2732/2732 [==============================] - 988s 362ms/step - loss: 1.2970 - accuracy: 0.5915 - val_loss: 1.3086 - val_accuracy: 0.5906\n",
      "Epoch 6/40\n",
      "2732/2732 [==============================] - 1027s 376ms/step - loss: 1.2663 - accuracy: 0.5999 - val_loss: 1.2851 - val_accuracy: 0.5990\n",
      "Epoch 7/40\n",
      "2732/2732 [==============================] - 1046s 383ms/step - loss: 1.2422 - accuracy: 0.6067 - val_loss: 1.2767 - val_accuracy: 0.6011\n",
      "Epoch 8/40\n",
      "2732/2732 [==============================] - 1026s 375ms/step - loss: 1.2228 - accuracy: 0.6123 - val_loss: 1.2772 - val_accuracy: 0.6018\n",
      "Epoch 9/40\n",
      "2732/2732 [==============================] - 1025s 375ms/step - loss: 1.2055 - accuracy: 0.6164 - val_loss: 1.2640 - val_accuracy: 0.6062\n",
      "Epoch 10/40\n",
      "2732/2732 [==============================] - 1036s 379ms/step - loss: 1.1908 - accuracy: 0.6208 - val_loss: 1.2595 - val_accuracy: 0.6094\n",
      "Epoch 11/40\n",
      "2732/2732 [==============================] - 1060s 388ms/step - loss: 1.1769 - accuracy: 0.6243 - val_loss: 1.2587 - val_accuracy: 0.6093\n",
      "Epoch 12/40\n",
      "2732/2732 [==============================] - 1053s 385ms/step - loss: 1.1653 - accuracy: 0.6274 - val_loss: 1.2568 - val_accuracy: 0.6098\n",
      "Epoch 13/40\n",
      "2732/2732 [==============================] - 1023s 374ms/step - loss: 1.1544 - accuracy: 0.6303 - val_loss: 1.2529 - val_accuracy: 0.6142\n",
      "Epoch 14/40\n",
      "2732/2732 [==============================] - 1018s 373ms/step - loss: 1.1459 - accuracy: 0.6327 - val_loss: 1.2535 - val_accuracy: 0.6140\n",
      "Epoch 15/40\n",
      "2732/2732 [==============================] - 893s 327ms/step - loss: 1.1355 - accuracy: 0.6354 - val_loss: 1.2617 - val_accuracy: 0.6148\n",
      "Epoch 16/40\n",
      "2732/2732 [==============================] - 1043s 382ms/step - loss: 1.1273 - accuracy: 0.6374 - val_loss: 1.2616 - val_accuracy: 0.6135\n",
      "Epoch 17/40\n",
      "2732/2732 [==============================] - 1039s 380ms/step - loss: 1.1197 - accuracy: 0.6403 - val_loss: 1.2639 - val_accuracy: 0.6155\n",
      "Epoch 18/40\n",
      "2732/2732 [==============================] - 1033s 378ms/step - loss: 1.1122 - accuracy: 0.6419 - val_loss: 1.2646 - val_accuracy: 0.6150\n",
      "Epoch 19/40\n",
      "2732/2732 [==============================] - 1034s 378ms/step - loss: 1.1050 - accuracy: 0.6439 - val_loss: 1.2651 - val_accuracy: 0.6167\n",
      "Epoch 20/40\n",
      "2732/2732 [==============================] - 1023s 374ms/step - loss: 1.0979 - accuracy: 0.6459 - val_loss: 1.2651 - val_accuracy: 0.6155\n",
      "Epoch 21/40\n",
      "2732/2732 [==============================] - 908s 332ms/step - loss: 1.0918 - accuracy: 0.6471 - val_loss: 1.2722 - val_accuracy: 0.6178\n",
      "Epoch 22/40\n",
      "2732/2732 [==============================] - 994s 364ms/step - loss: 1.0854 - accuracy: 0.6487 - val_loss: 1.2788 - val_accuracy: 0.6162\n",
      "Epoch 23/40\n",
      "2732/2732 [==============================] - 995s 364ms/step - loss: 1.0793 - accuracy: 0.6503 - val_loss: 1.2850 - val_accuracy: 0.6170\n",
      "Epoch 24/40\n",
      "2732/2732 [==============================] - 1032s 378ms/step - loss: 1.0742 - accuracy: 0.6522 - val_loss: 1.2826 - val_accuracy: 0.6171\n",
      "Epoch 25/40\n",
      "2732/2732 [==============================] - 1038s 380ms/step - loss: 1.0690 - accuracy: 0.6532 - val_loss: 1.2861 - val_accuracy: 0.6182\n",
      "Epoch 26/40\n",
      "2732/2732 [==============================] - 1019s 373ms/step - loss: 1.0647 - accuracy: 0.6542 - val_loss: 1.2876 - val_accuracy: 0.6164\n",
      "Epoch 27/40\n",
      "2732/2732 [==============================] - 994s 364ms/step - loss: 1.0590 - accuracy: 0.6558 - val_loss: 1.2880 - val_accuracy: 0.6169\n",
      "Epoch 28/40\n",
      " 635/2732 [=====>........................] - ETA: 11:22 - loss: 1.0425 - accuracy: 0.6593"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for optimizer in OPTIMIZERS:\n",
    "    for i, epochs in enumerate(TEST_EPOCHS):\n",
    "        toc = time.time()\n",
    "\n",
    "        print(f\"{counter} - {optimizer} - {epochs}\")\n",
    "\n",
    "        input_layer = keras.layers.Input(shape=(SEQ_LEN, len(chars)))\n",
    "        x = LSTM(128, return_sequences=True)(input_layer)\n",
    "        x = LSTM(128, return_sequences=False)(x)\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        x = keras.layers.Dense(256, 'relu')(x)\n",
    "        x = keras.layers.Dense(128, 'relu')(x)\n",
    "        x = keras.layers.Dropout(0.2)(x)\n",
    "        output_layer = keras.layers.Dense(len(chars), activation=tf.nn.softmax)(x)\n",
    "\n",
    "        model = keras.Model(input_layer, output_layer)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "        es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, restore_best_weights=True)\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='weights3.best.tf',\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='auto',\n",
    "            save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "        history = model.fit(X_ohe, y_ohe, validation_split=0.2, callbacks=[es, model_checkpoint_callback], epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        model.load_weights(\"weights3.best.tf\")\n",
    "\n",
    "        whole_text = X[10].copy()\n",
    "\n",
    "        for i in range(GENERATE_NUMBER_OF_CHARS):\n",
    "            paragraph_ohe = np.zeros((1, SEQ_LEN, len(chars)))\n",
    "            for t, char in enumerate(seq):\n",
    "                paragraph_ohe[0, t, char_indices[char]] = 1\n",
    "            y_pred = model.predict(paragraph_ohe)\n",
    "            c = sample(y_pred[0], 0.5)\n",
    "            next_char = indices_char[c]\n",
    "            whole_text.append(next_char)\n",
    "            seq = whole_text[-SEQ_LEN:]\n",
    "\n",
    "        tic = time.time()\n",
    "\n",
    "        res[counter] = {\n",
    "            \"generated_text\": whole_text,\n",
    "            \"epochs\": epochs,\n",
    "            \"generated_chars\": GENERATE_NUMBER_OF_CHARS,\n",
    "            \"seq_len\": SEQ_LEN,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"time_run\": tic - toc,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "\n",
    "        counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_text</th>\n",
       "      <th>epochs</th>\n",
       "      <th>generated_chars</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>time_run</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>8731.709074</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>20538.951594</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>29551.615134</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>34871.355740</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>35776.481059</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>10757.317433</td>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>21745.829852</td>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>30520.307349</td>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>25887.351698</td>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>23387.064028</td>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      generated_text  epochs  generated_chars  \\\n",
       "0  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      10             2000   \n",
       "1  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      20             2000   \n",
       "2  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      30             2000   \n",
       "3  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      40             2000   \n",
       "4  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      50             2000   \n",
       "5  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      10             2000   \n",
       "6  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      20             2000   \n",
       "7  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      30             2000   \n",
       "8  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      40             2000   \n",
       "9  [ , d, u, r, s, l, e, y,  , o, f,  , n, u, m, ...      50             2000   \n",
       "\n",
       "   seq_len  batch_size      time_run optimizer  \n",
       "0       60         256   8731.709074      adam  \n",
       "1       60         256  20538.951594      adam  \n",
       "2       60         256  29551.615134      adam  \n",
       "3       60         256  34871.355740      adam  \n",
       "4       60         256  35776.481059      adam  \n",
       "5       60         256  10757.317433   rmsprop  \n",
       "6       60         256  21745.829852   rmsprop  \n",
       "7       60         256  30520.307349   rmsprop  \n",
       "8       60         256  25887.351698   rmsprop  \n",
       "9       60         256  23387.064028   rmsprop  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "GEKZvA1gyFFi"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated_text'] =  list(map(lambda x: \"\".join(x), df['generated_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Optimizer: adam\n",
      "Text:  dursley of number four privet drive were proud to say that  the reason of the corner to his forehead he couldnt see him off he was seen anything harry said he looked quickly suddenly he said mr weasley had happened out a put he stopped out of the stone hagrid was do you see how could they know and he reached the stadium he was fan do the stone stuff that all the troll said harry they had never been a treating straight behind him he had seen he was trying to with the dark school the dursleys the rest of the boy from the common stretched at the neck in the son who was wearing the bedroom so the goal cold thing that the day of the ground the crowd the car were was on the toocre and was the gryffindor for you that the dark food the door was saying a stridick and no one ron said but he said and they started about more behind his trouble he had to get out of the start that silver we mean he said the good open back on the witch courage which were all about the light every spelled his ball and the good and the wand said harry harry he raised the room was no one graving feeling the shop in a door and the broom and threw the snake was come on and he said and start at the room silver potter to see it to the crowd and hagrid hated it all hermione was all that he should see him furious so the supporting door of green your in his quirrell said the door and he said with his finger he said hagrid and he said he could creeve won this an old back of the ministry of a stuffs in the car what i read his eyes the magic three of the floor harry could remember how many bed he was a hut here he said what the little holidays later with the corridor to steal harry thought he said harry in the rest of the way in the station to still i go and go to the wall what was a witch the castle more thing and he ron and hermione shook the trolley for the only students of find the face where i know the shout his eyes of the castle i thought stepped at the train to the new spell and they were staying around the corridor and the witch she said well it as a secret h\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Optimizer: adam\n",
      "Text:  dursley of number four privet drive were proud to say that even for a large hat and the branches and seat out there was a start of the barrier harry thought harry was particularly holding the portrait of them at him but it was going to say it to see it he and he had to take a second letter behind him in his complete feeling harry said ron had whispered the dursleys were a great hall with the ministry of the stool harry had seen the portrait of the train in the car be said hermione ron head but the parcel sent of her nose it was having a good bear the real time to see of the other side a surprise and harry said they wanted to the table was going on there he was back to harry was the head of his neck to the door had been said ron harry students then they had forgotten in a table and a potter in the corridor and there was a tappe of his sealed professor mcgonagall said harry and it was for a fork the man said mrs weasley but chess harry went on the stall cartle started by malfoy and snape said harry nothing they were straightened the class parking and the most time she said with said ron ready to the ground said harry no said harry and hermione and down the door they had been broomed in the note to the door and heard him a bottle of the many professor mcgonagall had been a same magic below to see him said ron harry and he could be died and harry told him off the bludgers and the window and she hadnt been silently faintly like a shakence of the forest with his head they were wanding at him ron was into the house he said ron theres a green by ron and hermione said slipped a great hall he could have died him in slytherin had many and he was for the smell of a broom was lip and started back and the silence they cant be flatters of the door and pointed his drooping door he was a baby so with the platform to his face when he was a stabby more than a second seem to be a few desk the shop the smell was how they had been off his hand nothing they were his wand with a broomstick said harry and ron the bludgers the castle was filch and t\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "Optimizer: adam\n",
      "Text:  dursley of number four privet drive were proud to say that he hadnt done a long hand of bookshelves the castle and a little tonight the door and the troll became with a second harry thought malfoy with the crate of dudleys and petrified it more in all this was the house said ron was since harry and now the corridor harry took the castle they had somewhere said ron ron and harry and ron and hermione and plants it to cheer a bag of great headmaster i said harry the sorting second galloping said hermione said ron when they were saying the cauldron told him he tried to hurt the car when i can say it had gotten the dursleys because the table and gentlemen with stop from the castle and seemed to take him in the shoulder said harry didnt think they had a bundle and flutfered to wizards said hermione in the first not the baron had not so much as i said harry and harry shredded and belt up and holding the end of the stairs and harry and ron in an hour mouth there was a large potions and its a bad and ten the same chot but he was there the only things at the clug on the first the trouble thought i was the look wood said harry the stone and screaming ron said harry and ron was already as though he was as though the sort of more the world he had taken anything harry scared he must says his courage to the troll that the chasers head to the car i think in the room they could he said and gasped when a sir and and disappeared from the corner had have something have have hardly pointed the storms with the dashbure have been all the corner harry told him he and professor mcgonagall four words staring to stop him and the unicorns and impressing in the house as he said all the creath came for all harry potter and brought he had finished it was a firm shot shop she didnt say something as he said finally  said hagrid an old hand to the bookshelves and sent when the wooden world but what had just one of them couldnt have been to sit and size of what are you want to see the mirror later that harry and ron he had to be the turban said the portrait \n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "Optimizer: adam\n",
      "Text:  dursley of number four privet drive were proud to say that he was lost the dursleys the hat harry felt she said filch was day look at the first the stone where it was saying the roof the train everyone was made them not to do with harry when it was a lot of a houseelfs when he was but the dursleys asking he should abrot be set for a long charms and harry and hermione were a second platform professor mcgonagall were distant arm he got to his wand and several scared every more didnt make the boy and saying a real said harry any signed said wood flicking in an unicorn the dead  but he and ron and hermione and snape had to find ron were still any baron said mr weasley swept the dursleys said harry is slytherin she thought his own window into the crowd were so said harry the hat like a second make a second said harry said ron no was the car and he said the weasleys would ave got so he was carrying and a stall they had been filled at the stone the floor on his face and she was so harry he pushed his face one shooting the mirror had been trying to see his hand and seamus first years and this time harry thought it was a moment the staring flaming over the stairs and down the only and well the air he said im going to see her hand and the best of the thousand er in the hall rooster and standed the sitting on the wall looking at his own gloomy said malfoy i think its not him and the names and harry had really but the stands there was a sign i sincered he was still closed it they were the stone with a slight but had gotten him at once  he said saying that he was still uncle vernon he got to professor mcgonagall and the weasleys had professor snape all the damp into his homework he didnt meet the place and he was forgettin and he no dont youre going to mention anything there had been to the cloak past his side the weasley whispered he said and he said on the time stand the other two books the headless harry potter put them a safe with the dursleys and drive he said looking at him the teacher hat it wouldnt be a second day of gryffindor \n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "Optimizer: adam\n",
      "Text:  dursley of number four privet drive were proud to say that was clearing at the spiral they had all barely the letter but he could say the wizard and gasped shops sharp way the steering car let he whispered said ron headments to harry and ron but the car for a spell but the end of the great second stars and when the ball and he called her head the front of him with the teachers and walked standing by harry as they shook hermione harry said hermione i was saying a great trunk and seized his face face said harry the houseelf seemed to be gave anything here malfoy and different harry looked silent he was the bit of the three of the troll standard did the party the wall the come on i was slipped on the great hall was a sleeping alleyward harry stared at the crowd oh who was a couple of magic and the next side of hermiones said hagrid moved his candles and the staffedaces and the rest of a shuffling do the common room gringotts were the particularly of the hall and not then i dont know neville can are the dursleys had died in a wonderful head and said said ron seamus the stomach flickering harry should be the only one he said its the note of harry and ron and hermione still said hermione said hermione who had been harry he left the stars in the first there was on the window and the small sat remember harry he said he was a sorrow after the composite look at harry and they could that harry looked at the compost of the furious crate and was the fastest hair they were too he cant see the school when see you know he had harry to stop him there was no one they were looking at him and suddenly the all the stone stood on the letters and spotted as the anceling of harrys face they had some a group of the match of the head with the bludgers are the stone and gawning her shiny of the legs and spotted the dark stone was clearing at the that mustred though he didnt seem to see the glass and  ears with a party and was coming to the broomstick thought harry grabbing the door said hermione the great stat and he was hagrid griphook harry was sta\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Optimizer: rmsprop\n",
      "Text:  dursley of number four privet drive were proud to say that ron and hermione was books this they were a high broom she was now it was was should be lace the side off the way though a harry would mean and then harry wanted it was harry was a word pulled the light as though alone with his bear is said harry attack uncle vernon was a learting called studying scrawled at another who said hermione as a direction off the stop what harry walked him why are the team from you might i mean harry dont go down his wand still still had said harry to his bust harry was walked points his bed harry said his thats was as harry really that was worry was stopped out of the standers off the stort said something is this harry wanted to be that three was a surdiction with while as though about the way so me with the way the way and sir and he said he looked over the way off harry shopped as they got with a harry was ron had been asked to strist we had said harry first near bathround him they were going to cake the flaust seemed to be binds he threw the stone the green wildort looked and that best the bird down the hat looked at the end off professor mcgonagall harry was still on his ear he looked at the door window and waited out the look off a collect steet aarner the fire show when harry said the back sight off to him said ron harry whispered snape was back since shocked harry last his pear important on the mirror was howled harry down the houses harry said attack gake stay when the dursleys head something which was he was was showed the one off the ground hagrid was rans but harry what harry had said bright he was stared why all here started a wizard and that was going to read he looked and wands with dumbledore was warmously later harry class stay his tates in the end off the ground said at him harry still stay they were he was really when the mirror off it is he was that was about the three hands peering said said percy a great off the pate if the car and leaves were she was mulch he sweet back with the book what that howed the books show ha\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Optimizer: rmsprop\n",
      "Text:  dursley of number four privet drive were proud to say that ready at the kinchart bang the door and the moment the listening the was seamus acle of the passages he was started along surpassed his far harry asked a scape and was him and histing the second a card and meet who was that something in the right the class sweat the spare nasty of his soon of the way was on car sorting the cack at the way he was a few the less the an her pecton the window through the castle second harry said hermione had a could feel the final as neck to look the door and minated the family as staying at his really the bater the stunted acceenues all ron had large with his face again and the second in a hare and got the hand to lide the card and the dungeons and harry was rude he said harry with his fang his thank a took of the window the trees spell harry said holding a bulled the cloak at the leave harry was he had said hermione to say it said the stone of drived the back on the dursleys they had his ay the troll of the wall madam hang and he had been a mounting a room off the corridor said harry heard and staring a head the lipped forward he was forcing a sharp with a window of all ourse  the bat so one into his hand to the fire is the last way back and the house had so harry praces with the wall so only and the sarw of malfoy the other with spell the famous would forceated across and harry how worked to the dark at harry was as the start but the head and hermiones and the one was a shall a than which was they walked secret a back harry said wast a gog  they was he had a potions and something at her with the seating was no wizard and made the window in the wall off the enchen on the stone along with the last shat to the hall said said harry here  you was a wasting at the head harry let the forest the window the fororest the rest weasley said ron before the standing in harry and hermione the starth to any shrieked the whole was said from the window actude the mank you was took a stare to the his way but the crowd harry said the gryffindor muggle o\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "Optimizer: rmsprop\n",
      "Text:  dursley of number four privet drive were proud to say that front of the feet fan with the fer charms the changers he said banding at harry seemed to have said ron the mirror and edge on the dedy portrait he was working on the car that i could have far the remoxe as in hangs harry said harry bad an a bar was a dean was was could what ill something they were an hoot said snape i seem him the same lessatie fluffy and could harry we mached what the straight the dark find harry started to harry to harry and harry didnt look on the car and harry stood the dark far the same said harry harry had had large a dark on harry then they thought the sharp harry had snapped on the corridor and stared at face harry looked at the rest of the mirror all harry had door he had but i dumbledore every had mr weasley had had the show it was they could get no the gatched a clear of pose the straight of harry that the me and he said the ghost was that he was a compled the car had a samoon the face with gwost in the fore who was so said ron how like the face harry looked ron the car he had all down of his owl direction what was going harry had the front of the way behind the floor arms harry was to the corridor the same rope harry and he many harry had that he was  the first start the said ron of the car name all  no one what had come and go was to hear his hand harry said a different brother they said dark  of the way vanished the stand of the shoulder that he said snape started he started the moment they were but i was a stick and steal fang the car that you call with the thing the greet home of the shell people had came was froxed the sort of the good fore what the hall behind the corridor everyone had shouted to stool harry did you can train he was have report  and he learned no one harry said harry snape shouted on hagrids patch the door the changer was roing he said the dark far they were broke so harry and harry said he streaked on the chamber and the floor and down here the shorp of pocket he had been the that said e the door behind him harry\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "Optimizer: rmsprop\n",
      "Text:  dursley of number four privet drive were proud to say that  this come of the staff and close the pution to whethered and where said watch the spat and they said the ginny to the great harry had said hagrid had done had to the teachers and would a three of his back against them off the second talk and a hidden back and when the second the common room in the offeefloods to a stranger of the second he was stood the same and the corridor with his best at the letter he was a toed harry may with the room starting to a few the magic of the little and for the boy and porned the bottle he was there in the boy and some even foreet him they were harry had shouted and come of hogwarts and from them they would have shouted as he was off his of a cad something said hermione at all the low does and show started at the corridor was to lib it harry and hermione had stopped out of the end and said a brickent he was although hagrid malfoy harry could have been wand in the malfoy was starting to his lockhart as the cold of her wor are the other the boy the other in the day hand the books of said starved to you he was a second of the shook of a beal mame he was seemed to the stone harry was in the stone of half to see the people said wood said what he had to the stone and and get back on to the cloak on the way in the stone of dester but harry shake said what all the stone about all he was allowed to the burd of something at the mottering manon he said fire the was in the big it had have to couldnt his head dumbledore what he was the floor before the same behind the arms and seemed on the sudden behind the staircase and he was a gallaon the believes with a walling to the allent and seemed off a stood the corridor and which harry and hermione in the cold both to with the boy what he was a stood something haid said whats he was a class of them at the the foot and stand of a same by the really werent said hermione had never three the room and the floors and to the way to harry was fierce but he was been and a second again moment the extrained the \n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "Optimizer: rmsprop\n",
      "Text:  dursley of number four privet drive were proud to say that they had hy nearly remembered after as the it was looking on saad a shell was saad of it is it was already looked looking and taken his reason and hermione er it couldnt see the start professor sproom very offect underground in a speed and setuntion to she was said harry frog saad he was stared fred the end of the high not as it was for the ceiling to people there because the wizard first morning down the door to safe in a look of his ording they potter didnt be a really because with a sort of the lead in the end of the very weasley stared to bed go but when the broom portrait a moment with it a pink to the back not a decenters and it was can  of his troom and shook and caught because people who found out when they looked at his wands from the hat to the gool and potter the can never knew  when he said hermione in the threeghh of his thing lockhart dont be asked with his books the walls of the next how questiones of his way     what they really for really and who got one who was in potter going to catch him going to harry forest their good in the stool a few from and came continued to go one he saskeral ron and they didnt have a little and stood out of the never and save the station back in the portrait of the last house a fire so he caught the other unplease in her never teacher called the whole sat to harry and ron and hermione potter the same the gryffindor then for his first entorable quills with his first desk they appeared and hermione sat person he was at it and looked at the window the head came christmas face of the last again snape sleep the other bound his family whispered harry could see his broom and hermione he looked quickly out the can when a mouth and to his teacher beather but from the castle as he had so fore really found his ded before nearly alone thinking and potter because that just not a same the last  come probably my had a was affelies closer and better she head what was completely done in the hall some of professor professor binds come bac\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    epochs = df['epochs'].values\n",
    "    optimizers = df['optimizer'].values\n",
    "    texts = df['generated_text'].values\n",
    "    \n",
    "    print(f\"Epoch: {epochs[i]}\")\n",
    "    print(f\"Optimizer: {optimizers[i]}\")\n",
    "    print(f\"Text: {texts[i]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "DEEWbNfz0wq6"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_04.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
